{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Introduction\n",
    "\n",
    "Most machine learning workflows involve working with data, creating models, optimizing model parameters, and saving the trained models. This tutorial introduces you to a complete ML workflow implemented in PyTorch, with links to learn more about each of these concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.5942, 0.7193],\n",
      "        [0.8057, 0.1604],\n",
      "        [0.1688, 0.0891]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor from a list\n",
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "print(tensor1)\n",
    "\n",
    "# Create a tensor of zeros with shape (2, 3)\n",
    "tensor2 = torch.zeros(2, 3)\n",
    "print(tensor2)\n",
    "\n",
    "# Create a random tensor with shape (3, 2)\n",
    "tensor3 = torch.rand(3, 2)\n",
    "print(tensor3)\n",
    "\n",
    "# Performing operations on Tensors\n",
    "\n",
    "# Addition\n",
    "result_add = tensor1 + tensor2\n",
    "print(result_add)\n",
    "\n",
    "\n",
    "# Multiplication\n",
    "result_mul = tensor2 * 5\n",
    "print(result_mul)\n",
    "\n",
    "\n",
    "# Matrix multiplication\n",
    "result_matmul = torch.matmul(tensor2, tensor3)\n",
    "print(result_matmul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(31., grad_fn=<AddBackward0>)\n",
      "tensor(4.)\n",
      "tensor(27.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Perform a computation\n",
    "z = x**2 + y**3\n",
    "print(z)\n",
    "\n",
    "# Compute gradients\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input layer\n",
    "        self.relu = nn.ReLU()                          # Activation function\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "# Define the input size, hidden size, and output size of the neural network\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 10\n",
    "output_size = len(iris.target_names)\n",
    "\n",
    "\n",
    "# Instantiate the neural network\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# Convert datto PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.7783\n",
      "Epoch [20/100], Loss: 0.5399\n",
      "Epoch [30/100], Loss: 0.3921\n",
      "Epoch [40/100], Loss: 0.2934\n",
      "Epoch [50/100], Loss: 0.2166\n",
      "Epoch [60/100], Loss: 0.1639\n",
      "Epoch [70/100], Loss: 0.1284\n",
      "Epoch [80/100], Loss: 0.1050\n",
      "Epoch [90/100], Loss: 0.0902\n",
      "Epoch [100/100], Loss: 0.0800\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "   \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "   \n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_test_tensor = torch.LongTensor(y_test)\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "    print(f'Accuracy on the test set: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mconda38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
