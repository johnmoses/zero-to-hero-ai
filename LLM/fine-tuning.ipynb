{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 19:58:27.988803: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Check up environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"        \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'    \n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Let's load data from `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Bad_Practices', 'Good_Practices'],\n",
       "        num_rows: 6712\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"data.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bad_Practices': '<table alt=header>Title</table>',\n",
       " 'Good_Practices': \"<table alt='header'>Title</table>\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bad_Practices</th>\n",
       "      <th>Good_Practices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;table alt=header&gt;Title&lt;/table&gt;</td>\n",
       "      <td>&lt;table alt='header'&gt;Title&lt;/table&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;tr&gt;Content</td>\n",
       "      <td>&lt;tr&gt;Content&lt;/tr&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;h2 src='description'&gt;Content</td>\n",
       "      <td>&lt;h2 src='description'&gt;Content&lt;/h2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;table&gt;Link</td>\n",
       "      <td>&lt;table&gt;Link&lt;/table&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;img src='description'&gt;</td>\n",
       "      <td>&lt;img src='description' alt=''&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bad_Practices                      Good_Practices\n",
       "0  <table alt=header>Title</table>   <table alt='header'>Title</table>\n",
       "1                      <tr>Content                    <tr>Content</tr>\n",
       "2    <h2 src='description'>Content  <h2 src='description'>Content</h2>\n",
       "3                      <table>Link                 <table>Link</table>\n",
       "4          <img src='description'>      <img src='description' alt=''>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = pd.read_csv('./data.csv')\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Define model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}\n"
     ]
    }
   ],
   "source": [
    "special_tokens = tokenizer.special_tokens_map\n",
    "print(special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get trainable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Param = 768\n",
      "Total Params = 124439808\n",
      "% of trainable params = 0.0006171658509791337\n"
     ]
    }
   ],
   "source": [
    "def get_num_trainable_params(model):\n",
    "    total_params = 0\n",
    "    total_trainable_params = 0\n",
    "\n",
    "    for _ , params in model.named_parameters():\n",
    "        total_params += params.numel()\n",
    "\n",
    "    if params.requires_grad:\n",
    "        total_trainable_params += params.numel()\n",
    "\n",
    "    return f\"Trainable Param = {total_trainable_params}\\nTotal Params = {total_params}\\n% of trainable params = {100*(total_trainable_params/total_params)}\"\n",
    "\n",
    "print(get_num_trainable_params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad_token for the tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data = dataset[\"train\"].select([i for i in range(len(dataset[\"train\"])) if i % 10 != 0])  # Use 90% of the data for training\n",
    "val_data = dataset[\"train\"].select([i for i in range(len(dataset[\"train\"])) if i % 10 == 0])  # Use 10% of the data for validation\n",
    "\n",
    "# Tokenize the input and target sequences\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples['Bad_Practices'], return_tensors='pt', padding='max_length', max_length=512, truncation=True)\n",
    "    labels = tokenizer(examples['Good_Practices'], return_tensors='pt', padding='max_length', max_length=512, truncation=True)\n",
    "    return {'input_ids': inputs['input_ids'], 'labels': labels['input_ids']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply tokenization to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_data = train_data.map(tokenize_function, batched=True)\n",
    "tokenized_val_data = val_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Bad_Practices', 'Good_Practices', 'input_ids', 'labels'],\n",
       "    num_rows: 6040\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Bad_Practices', 'Good_Practices', 'input_ids', 'labels'],\n",
       "    num_rows: 672\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "It is now time to fine-tune. We first of all define and set the training argruments and trainer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./gpt2-v1',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=0.5,\n",
    "    per_device_train_batch_size=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    logging_dir='./gpt2-log',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_data,\n",
    "    eval_dataset=tokenized_val_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca77d6372cf4589961d9faf48a5277b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1858, 'grad_norm': 0.6013979911804199, 'learning_rate': 4.668874172185431e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22b51bacb63417f84bde452de682ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021580373868346214, 'eval_runtime': 45.2643, 'eval_samples_per_second': 14.846, 'eval_steps_per_second': 1.856, 'epoch': 0.03}\n",
      "{'loss': 0.0249, 'grad_norm': 0.5122044086456299, 'learning_rate': 4.337748344370861e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2ab8bec60343d2af992d7163991bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.019640132784843445, 'eval_runtime': 45.0179, 'eval_samples_per_second': 14.927, 'eval_steps_per_second': 1.866, 'epoch': 0.07}\n",
      "{'loss': 0.0225, 'grad_norm': 0.5484234690666199, 'learning_rate': 4.006622516556292e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992c5109dad54c79becca6da34b70d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01877715066075325, 'eval_runtime': 45.0129, 'eval_samples_per_second': 14.929, 'eval_steps_per_second': 1.866, 'epoch': 0.1}\n",
      "{'loss': 0.022, 'grad_norm': 0.45391297340393066, 'learning_rate': 3.675496688741722e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb321dff11545b08302b442a68264e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018603404983878136, 'eval_runtime': 45.0215, 'eval_samples_per_second': 14.926, 'eval_steps_per_second': 1.866, 'epoch': 0.13}\n",
      "{'loss': 0.0201, 'grad_norm': 0.4729527533054352, 'learning_rate': 3.3443708609271526e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d430ba545e9f46819f7c933032c175f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017404144629836082, 'eval_runtime': 45.1453, 'eval_samples_per_second': 14.885, 'eval_steps_per_second': 1.861, 'epoch': 0.17}\n",
      "{'loss': 0.0195, 'grad_norm': 0.7584893107414246, 'learning_rate': 3.0132450331125826e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ae13a1f9464c3e8455e73cb519ad22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01764616183936596, 'eval_runtime': 45.2056, 'eval_samples_per_second': 14.865, 'eval_steps_per_second': 1.858, 'epoch': 0.2}\n",
      "{'loss': 0.0193, 'grad_norm': 0.47831717133522034, 'learning_rate': 2.6821192052980134e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c377c941094346848ccec949387cefc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01692104898393154, 'eval_runtime': 45.1284, 'eval_samples_per_second': 14.891, 'eval_steps_per_second': 1.861, 'epoch': 0.23}\n",
      "{'loss': 0.0195, 'grad_norm': 0.6444122791290283, 'learning_rate': 2.3509933774834437e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3b82faefc7426c8190eaeace6dbfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01767946407198906, 'eval_runtime': 45.1783, 'eval_samples_per_second': 14.874, 'eval_steps_per_second': 1.859, 'epoch': 0.26}\n",
      "{'loss': 0.0191, 'grad_norm': 0.45875084400177, 'learning_rate': 2.0198675496688745e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7daa99ad5c0940a6afc270150e62fcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01710532046854496, 'eval_runtime': 45.1137, 'eval_samples_per_second': 14.896, 'eval_steps_per_second': 1.862, 'epoch': 0.3}\n",
      "{'loss': 0.0193, 'grad_norm': 0.6492225527763367, 'learning_rate': 1.688741721854305e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d62932390d3421d8de37c11cebf088d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017163880169391632, 'eval_runtime': 45.1676, 'eval_samples_per_second': 14.878, 'eval_steps_per_second': 1.86, 'epoch': 0.33}\n",
      "{'loss': 0.0183, 'grad_norm': 0.4945014715194702, 'learning_rate': 1.3576158940397351e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73433aa807ec4565af6e208917939c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01691201515495777, 'eval_runtime': 45.3291, 'eval_samples_per_second': 14.825, 'eval_steps_per_second': 1.853, 'epoch': 0.36}\n",
      "{'loss': 0.018, 'grad_norm': 0.4645948112010956, 'learning_rate': 1.0264900662251655e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633350b4791746f48401c4f2a169114c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016805116087198257, 'eval_runtime': 45.2274, 'eval_samples_per_second': 14.858, 'eval_steps_per_second': 1.857, 'epoch': 0.4}\n",
      "{'loss': 0.0179, 'grad_norm': 0.5832744240760803, 'learning_rate': 6.95364238410596e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e9def6c7b34a5196cac52c3cc762ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01646888628602028, 'eval_runtime': 45.3336, 'eval_samples_per_second': 14.823, 'eval_steps_per_second': 1.853, 'epoch': 0.43}\n",
      "{'loss': 0.0185, 'grad_norm': 0.5311223268508911, 'learning_rate': 3.642384105960265e-06, 'epoch': 0.46}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee2447e5ec943e788be70d22f7aa722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01642460562288761, 'eval_runtime': 45.2078, 'eval_samples_per_second': 14.865, 'eval_steps_per_second': 1.858, 'epoch': 0.46}\n",
      "{'loss': 0.0175, 'grad_norm': 0.6129200458526611, 'learning_rate': 3.3112582781456954e-07, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3259283bb2eb4f87be84fa37582d1c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016410328447818756, 'eval_runtime': 45.3566, 'eval_samples_per_second': 14.816, 'eval_steps_per_second': 1.852, 'epoch': 0.5}\n",
      "{'train_runtime': 1770.1844, 'train_samples_per_second': 1.706, 'train_steps_per_second': 0.853, 'train_loss': 0.030721422220697465, 'epoch': 0.5}\n",
      "CPU times: user 9min 49s, sys: 1min 3s, total: 10min 53s\n",
      "Wall time: 29min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1510, training_loss=0.030721422220697465, metrics={'train_runtime': 1770.1844, 'train_samples_per_second': 1.706, 'train_steps_per_second': 0.853, 'total_flos': 789101936640000.0, 'train_loss': 0.030721422220697465, 'epoch': 0.5})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9140aa39bb746abb319fe348e8ba52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.02\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f'Perplexity: {math.exp(eval_results[\"eval_loss\"]):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mforge39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
