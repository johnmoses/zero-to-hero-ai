{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive and Gradient Boosting Classification\n",
    "\n",
    "This are powerful tools used to speed up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniforge3/envs/mforge39/lib/python3.9/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "import warnings\n",
    "from time import time\n",
    "from itertools import product\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# needed for HistGradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "# from sklearn.inspection import partial_dependence, plot_partial_dependence\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(start='2000', end='2018', task='classification', holding_period=1, dropna=False):\n",
    "    \n",
    "    idx = pd.IndexSlice\n",
    "    target = f'target_{holding_period}m'\n",
    "    with pd.HDFStore('../xdata/assets.h5') as store:\n",
    "        df = store['engineered_features']\n",
    "\n",
    "    if start is not None and end is not None:\n",
    "        df = df.loc[idx[:, start: end], :]\n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "        \n",
    "    y = (df[target]>0).astype(int)\n",
    "    X = df.drop([c for c in df.columns if c.startswith('target')], axis=1)\n",
    "    return y, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['year', 'month', 'age', 'msize', 'sector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integer encoding of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_cats(df, cats=['sector']):\n",
    "    cat_cols = ['year', 'month', 'age', 'msize'] + cats\n",
    "    for cat in cats:\n",
    "        df[cat] = pd.factorize(df[cat])[0]\n",
    "    df.loc[:, cat_cols] = df.loc[:, cat_cols].fillna(-1).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_data(df, cols=cat_cols[:-1]):\n",
    "    df = pd.get_dummies(df,\n",
    "                        columns=cols + ['sector'],\n",
    "                        prefix=cols + [''],\n",
    "                        prefix_sep=['_'] * len(cols) + [''])\n",
    "    return df.rename(columns={c: c.replace('.0', '') for c in df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holdout_set(target, features, period=6):\n",
    "    idx = pd.IndexSlice\n",
    "    label = target.name\n",
    "    dates = np.sort(y.index.get_level_values('date').unique())\n",
    "    cv_start, cv_end = dates[0], dates[-period - 2]\n",
    "    holdout_start, holdout_end = dates[-period - 1], dates[-1]\n",
    "\n",
    "    df = features.join(target.to_frame())\n",
    "    train = df.loc[idx[:, cv_start: cv_end], :]\n",
    "    y_train, X_train = train[label], train.drop(label, axis=1)\n",
    "\n",
    "    test = df.loc[idx[:, holdout_start: holdout_end], :]\n",
    "    y_test, X_test = test[label], test.drop(label, axis=1)\n",
    "    return y_train, X_train, y_test, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No object named engineered_features in the file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y, features \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m X_dummies \u001b[38;5;241m=\u001b[39m get_one_hot_data(features)\n\u001b[1;32m      3\u001b[0m X_factors \u001b[38;5;241m=\u001b[39m factorize_cats(features)\n",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(start, end, task, holding_period, dropna)\u001b[0m\n\u001b[1;32m      4\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mholding_period\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mHDFStore(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../xdata/assets.h5\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m store:\n\u001b[0;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mengineered_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[idx[:, start: end], :]\n",
      "File \u001b[0;32m~/miniforge3/envs/mforge39/lib/python3.9/site-packages/pandas/io/pytables.py:602\u001b[0m, in \u001b[0;36mHDFStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mforge39/lib/python3.9/site-packages/pandas/io/pytables.py:812\u001b[0m, in \u001b[0;36mHDFStore.get\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    810\u001b[0m group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_node(key)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo object named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in the file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_group(group)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No object named engineered_features in the file'"
     ]
    }
   ],
   "source": [
    "y, features = get_data()\n",
    "X_dummies = get_one_hot_data(features)\n",
    "X_factors = factorize_cats(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = DecisionTreeClassifier(\n",
    "    criterion='gini', \n",
    "    splitter='best',\n",
    "    max_depth=1, \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=20, \n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None, \n",
    "    random_state=None, \n",
    "    max_leaf_nodes=None, \n",
    "    min_impurity_decrease=0.0,  \n",
    "    class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    # base_estimator=base_estimator,\n",
    "    n_estimators=100,\n",
    "    learning_rate=1.0,\n",
    "    algorithm='SAMME.R',\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'adaboost'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
